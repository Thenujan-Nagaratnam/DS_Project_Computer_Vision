{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69958f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:09.681120Z",
     "iopub.status.busy": "2023-10-21T11:16:09.680752Z",
     "iopub.status.idle": "2023-10-21T11:16:26.514909Z",
     "shell.execute_reply": "2023-10-21T11:16:26.513932Z"
    },
    "papermill": {
     "duration": 16.849943,
     "end_time": "2023-10-21T11:16:26.517390",
     "exception": false,
     "start_time": "2023-10-21T11:16:09.667447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\r\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\r\n",
      "Collecting open-clip-torch\r\n",
      "  Downloading open_clip_torch-2.22.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting faiss-gpu\r\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\r\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n",
      "Requirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.15.1)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (2023.6.3)\r\n",
      "Collecting ftfy (from open-clip-torch)\r\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.16.4)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.1.99)\r\n",
      "Requirement already satisfied: protobuf<4 in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (3.20.3)\r\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch) (0.9.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open-clip-torch) (3.1.2)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\r\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->open-clip-torch) (0.2.6)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (2023.6.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open-clip-torch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open-clip-torch) (0.3.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (1.23.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open-clip-torch) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open-clip-torch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\r\n",
      "Installing collected packages: faiss-gpu, ftfy, gdown, open-clip-torch\r\n",
      "Successfully installed faiss-gpu-1.7.2 ftfy-6.1.1 gdown-4.7.1 open-clip-torch-2.22.0\r\n"
     ]
    }
   ],
   "source": [
    "# #Setup Gdrive file download extention\n",
    "!pip install gdown open-clip-torch faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e2993c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:26.546438Z",
     "iopub.status.busy": "2023-10-21T11:16:26.545657Z",
     "iopub.status.idle": "2023-10-21T11:16:26.550405Z",
     "shell.execute_reply": "2023-10-21T11:16:26.549523Z"
    },
    "papermill": {
     "duration": 0.021184,
     "end_time": "2023-10-21T11:16:26.552469",
     "exception": false,
     "start_time": "2023-10-21T11:16:26.531285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1BFAJfzzeaUGsPoYELS86HIutJ43D-vat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1afe73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:26.581040Z",
     "iopub.status.busy": "2023-10-21T11:16:26.580731Z",
     "iopub.status.idle": "2023-10-21T11:16:34.559175Z",
     "shell.execute_reply": "2023-10-21T11:16:34.558395Z"
    },
    "papermill": {
     "duration": 7.995783,
     "end_time": "2023-10-21T11:16:34.561627",
     "exception": false,
     "start_time": "2023-10-21T11:16:26.565844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open_clip\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "import faiss\n",
    "import copy\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b9f5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.591081Z",
     "iopub.status.busy": "2023-10-21T11:16:34.590796Z",
     "iopub.status.idle": "2023-10-21T11:16:34.602648Z",
     "shell.execute_reply": "2023-10-21T11:16:34.601754Z"
    },
    "papermill": {
     "duration": 0.029043,
     "end_time": "2023-10-21T11:16:34.604693",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.575650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_precision_at_k(ranked_targets: np.ndarray,\n",
    "                           k: int) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the precision at k.\n",
    "    Args:\n",
    "        ranked_targets: A boolean array of retrieved targets, True if relevant and False otherwise.\n",
    "        k: The number of examples to consider\n",
    "\n",
    "    Returns: The precision at k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    assert ranked_targets.size >= k, ValueError('Relevance score length < k')\n",
    "    return np.mean(ranked_targets[:k])\n",
    "\n",
    "def compute_average_precision(ranked_targets: np.ndarray,\n",
    "                              gtp: int) -> float:\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    Computes the average precision.\n",
    "    Args:\n",
    "        ranked_targets: A boolean array of retrieved targets, True if relevant and False otherwise.\n",
    "        gtp: ground truth positives.\n",
    "\n",
    "    Returns:\n",
    "        The average precision.\n",
    "    \"\"\"\n",
    "    assert gtp >= 1\n",
    "    # compute precision at rank only for positive targets\n",
    "    out = [compute_precision_at_k(ranked_targets, k + 1) for k in range(ranked_targets.size) if ranked_targets[k]]\n",
    "    if len(out) == 0:\n",
    "        # no relevant targets in top1000 results\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.sum(out) / gtp\n",
    "\n",
    "\n",
    "def calculate_map(ranked_retrieval_results: np.ndarray,\n",
    "                  query_labels: np.ndarray,\n",
    "                  gallery_labels: np.ndarray) -> float:\n",
    "    \n",
    "    global current_retrievals, gpt\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates the mean average precision.\n",
    "    Args:\n",
    "        ranked_retrieval_results: A 2D array of ranked retrieval results (shape: n_queries x 1000), because we use\n",
    "                                top1000 retrieval results.\n",
    "        query_labels: A 1D array of query class labels (shape: n_queries).\n",
    "        gallery_labels: A 1D array of gallery class labels (shape: n_gallery_items).\n",
    "    Returns:\n",
    "        The mean average precision.\n",
    "    \"\"\"\n",
    "    assert ranked_retrieval_results.ndim == 2\n",
    "    assert ranked_retrieval_results.shape[1] == 1000\n",
    "\n",
    "    class_average_precisions = []\n",
    "    current_retrievals = []\n",
    "\n",
    "    class_ids, class_counts = np.unique(gallery_labels, return_counts=True)\n",
    "    class_id2quantity_dict = dict(zip(class_ids, class_counts))\n",
    "    for gallery_indices, query_class_id in tqdm(\n",
    "                            zip(ranked_retrieval_results, query_labels),\n",
    "                            total=len(query_labels)):\n",
    "        # Checking that no image is repeated in the retrival results\n",
    "        assert len(np.unique(gallery_indices)) == len(gallery_indices), \\\n",
    "                    ValueError('Repeated images in retrieval results')\n",
    "\n",
    "        current_retrieval = gallery_labels[gallery_indices] == query_class_id\n",
    "        gpt = class_id2quantity_dict[query_class_id]\n",
    "        \n",
    "        current_retrievals.append(current_retrieval)\n",
    "\n",
    "        class_average_precisions.append(\n",
    "            compute_average_precision(current_retrieval, gpt)\n",
    "        )\n",
    "\n",
    "    mean_average_precision = np.mean(class_average_precisions)\n",
    "    return mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48fc9111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.632534Z",
     "iopub.status.busy": "2023-10-21T11:16:34.632257Z",
     "iopub.status.idle": "2023-10-21T11:16:34.639782Z",
     "shell.execute_reply": "2023-10-21T11:16:34.638838Z"
    },
    "papermill": {
     "duration": 0.023844,
     "end_time": "2023-10-21T11:16:34.641869",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.618025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_l2_distances(query, gallery):\n",
    "    return np.linalg.norm(gallery - query, axis=1)\n",
    "\n",
    "def get_k_nearest_neighbors(distances, k):\n",
    "    indices = np.argsort(distances)[:k]\n",
    "    return indices\n",
    "\n",
    "def get_similiarity_l2(embeddings_gallery, embeddings_query, k):\n",
    "    print('Processing indices...')\n",
    "\n",
    "    s = time.time()\n",
    "\n",
    "    scores = []\n",
    "    indices = []\n",
    "\n",
    "    for query in embeddings_query:\n",
    "        distances = calculate_l2_distances(query, embeddings_gallery)\n",
    "        nearest_indices = get_k_nearest_neighbors(distances, k)\n",
    "        scores.append(distances[nearest_indices])\n",
    "        indices.append(nearest_indices)\n",
    "\n",
    "    e = time.time()\n",
    "\n",
    "    print(f'Finished processing indices, took {e - s}s')\n",
    "    return np.array(scores), np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8621187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.670471Z",
     "iopub.status.busy": "2023-10-21T11:16:34.669851Z",
     "iopub.status.idle": "2023-10-21T11:16:34.675111Z",
     "shell.execute_reply": "2023-10-21T11:16:34.674238Z"
    },
    "papermill": {
     "duration": 0.021786,
     "end_time": "2023-10-21T11:16:34.677197",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.655411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_indices_to_labels(indices, labels):\n",
    "    indices_copy = copy.deepcopy(indices)\n",
    "    for row in indices_copy:\n",
    "        for j in range(len(row)):\n",
    "            row[j] = labels[row[j]]\n",
    "    return indices_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ef0019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.705020Z",
     "iopub.status.busy": "2023-10-21T11:16:34.704738Z",
     "iopub.status.idle": "2023-10-21T11:16:34.810063Z",
     "shell.execute_reply": "2023-10-21T11:16:34.809082Z"
    },
    "papermill": {
     "duration": 0.121663,
     "end_time": "2023-10-21T11:16:34.812186",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.690523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if th.cuda.is_available() else 'cpu';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c36fe",
   "metadata": {
    "papermill": {
     "duration": 0.012836,
     "end_time": "2023-10-21T11:16:34.838377",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.825541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdbacdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.866410Z",
     "iopub.status.busy": "2023-10-21T11:16:34.866073Z",
     "iopub.status.idle": "2023-10-21T11:16:34.875861Z",
     "shell.execute_reply": "2023-10-21T11:16:34.874841Z"
    },
    "papermill": {
     "duration": 0.026436,
     "end_time": "2023-10-21T11:16:34.877936",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.851500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_image(image_file):\n",
    "    img = cv2.imread(\n",
    "        image_file, cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION\n",
    "    )\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if img is None:\n",
    "        raise ValueError('Failed to read {}'.format(image_file))\n",
    "    return img\n",
    "\n",
    "class SubmissionDataset(Dataset):\n",
    "    def __init__(self, root, annotation_file, transforms, with_bbox=False):\n",
    "        self.root = root\n",
    "        self.imlist = pd.read_csv(annotation_file)\n",
    "        self.transforms = transforms\n",
    "        self.with_bbox = with_bbox\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cv2.setNumThreads(6)\n",
    "\n",
    "        full_imname = os.path.join(self.root, self.imlist['img_path'][index])\n",
    "        img = read_image(full_imname)\n",
    "\n",
    "        if self.with_bbox:\n",
    "            x, y, w, h = self.imlist.loc[index, 'bbox_x':'bbox_h']\n",
    "            img = img[y:y+h, x:x+w, :]\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transforms(img)\n",
    "        product_id = self.imlist['product_id'][index]\n",
    "        return img, product_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00ac69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.906815Z",
     "iopub.status.busy": "2023-10-21T11:16:34.906513Z",
     "iopub.status.idle": "2023-10-21T11:16:34.918143Z",
     "shell.execute_reply": "2023-10-21T11:16:34.917310Z"
    },
    "papermill": {
     "duration": 0.028383,
     "end_time": "2023-10-21T11:16:34.920244",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.891861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transform():  \n",
    "    transform = T.Compose([\n",
    "            T.Resize(\n",
    "                size=(224, 224), \n",
    "                interpolation=T.InterpolationMode.BICUBIC,\n",
    "                antialias=True),\n",
    "            T.ToTensor(), \n",
    "            T.Normalize(\n",
    "                mean=(0.48145466, 0.4578275, 0.40821073), \n",
    "                std=(0.26862954, 0.26130258, 0.27577711)\n",
    "            )\n",
    "        ])\n",
    "    return transform\n",
    "\n",
    "@th.no_grad()\n",
    "def get_feature_vector(model_vit_h_14, model_vit_l_14, model_convnext_320_focal, dataloader, weight, use_cuda=True):\n",
    "    features = []\n",
    "    product_id = []\n",
    "    \n",
    "    for imgs, p_id in tqdm(dataloader):\n",
    "        if use_cuda:\n",
    "            imgs = imgs.cuda()\n",
    "            \n",
    "#         print(th.squeeze(model_vit_h_14(imgs.half())).shape, th.squeeze(model_vit_l_14(imgs.half())).shape)\n",
    "        feature_model_vit_h_14, feature_model_vit_l_14, feature_model_convnext_320_focal = th.squeeze(model_vit_h_14(imgs.half())).detach().cpu().numpy().astype(np.float32), th.squeeze(model_vit_l_14(imgs.half())).detach().cpu().numpy().astype(np.float32), th.squeeze(model_convnext_320_focal(imgs.half())).detach().cpu().numpy().astype(np.float32)\n",
    "        \n",
    "        feature_model_vit_h_14 = th.from_numpy(feature_model_vit_h_14)\n",
    "        feature_model_vit_l_14 = th.from_numpy(weight[1]*feature_model_vit_l_14)\n",
    "        feature_model_convnext_320_focal = th.from_numpy(weight[0]*feature_model_convnext_320_focal)\n",
    "        \n",
    "        feature = th.cat((feature_model_vit_h_14, feature_model_vit_l_14, feature_model_convnext_320_focal), dim=1)\n",
    "#         print(feature.shape)\n",
    "        features.append(feature)\n",
    "        product_id.append(th.squeeze(p_id).detach().cpu().numpy())\n",
    "\n",
    "    return np.concatenate(features, axis=0), np.concatenate(product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16ba77",
   "metadata": {
    "papermill": {
     "duration": 0.014235,
     "end_time": "2023-10-21T11:16:34.948514",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.934279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Getting the CLIP model's embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b744eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:34.980102Z",
     "iopub.status.busy": "2023-10-21T11:16:34.979797Z",
     "iopub.status.idle": "2023-10-21T11:16:54.070653Z",
     "shell.execute_reply": "2023-10-21T11:16:54.069809Z"
    },
    "papermill": {
     "duration": 19.11069,
     "end_time": "2023-10-21T11:16:54.073197",
     "exception": false,
     "start_time": "2023-10-21T11:16:34.962507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path_large = '/kaggle/input/vit-l-14-final-weights/my_experiments/ViT-L-14-laion2b_s32b_b82k-image_net-v2-p10k-h&m-Arcface(k=3)-All-Epoch(4)-Reduce_LR_0.1/model_epoch_2_mAP3_0.52.pt'\n",
    "\n",
    "vit_backbone_vit_l_14 = open_clip.create_model_and_transforms('ViT-L-14', None)[0].visual\n",
    "vit_backbone_vit_l_14.load_state_dict(th.load(weights_path_large)['model_state_dict'])\n",
    "vit_backbone_vit_l_14.half()   # Apply half precision to the backbone model\n",
    "vit_backbone_vit_l_14.eval()   # Dropping unecessary layers\n",
    "model_vit_l_14 = vit_backbone_vit_l_14\n",
    "model_vit_l_14.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feccdad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:16:54.101954Z",
     "iopub.status.busy": "2023-10-21T11:16:54.101620Z",
     "iopub.status.idle": "2023-10-21T11:17:16.965207Z",
     "shell.execute_reply": "2023-10-21T11:17:16.964110Z"
    },
    "papermill": {
     "duration": 22.880656,
     "end_time": "2023-10-21T11:17:16.967790",
     "exception": false,
     "start_time": "2023-10-21T11:16:54.087134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path_huge = '/kaggle/input/vit-h-14-final-weights/model_weights.pt'\n",
    "\n",
    "vit_backbone_vit_h_14 = open_clip.create_model_and_transforms('ViT-H-14', None)[0].visual\n",
    "vit_backbone_vit_h_14.load_state_dict(th.load(weights_path_huge))\n",
    "vit_backbone_vit_h_14.half()   # Apply half precision to the backbone model\n",
    "vit_backbone_vit_h_14.eval()   # Dropping unecessary layers\n",
    "model_vit_h_14 = vit_backbone_vit_h_14\n",
    "model_vit_h_14.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9dae18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:16.995239Z",
     "iopub.status.busy": "2023-10-21T11:17:16.994735Z",
     "iopub.status.idle": "2023-10-21T11:17:28.309797Z",
     "shell.execute_reply": "2023-10-21T11:17:28.308911Z"
    },
    "papermill": {
     "duration": 11.331463,
     "end_time": "2023-10-21T11:17:28.312419",
     "exception": false,
     "start_time": "2023-10-21T11:17:16.980956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path_convnext_320_focal = '/kaggle/input/convnext-large-d-final-weights/my_experiments/convnext_large_d_320-laion2b_s29b_b131k_ft-image_net-v2-p10k-h&m-Arcface(k=3)-All-Epoch(2)-Reduce_LR_0.1/model_epoch_1_mAP3_0.55.pt'\n",
    "\n",
    "vit_backbone_convnext_320_focal = open_clip.create_model_and_transforms('convnext_large_d_320', None)[0].visual\n",
    "vit_backbone_convnext_320_focal.load_state_dict(th.load(weights_path_convnext_320_focal)['model_state_dict'])\n",
    "vit_backbone_convnext_320_focal.half()   # Apply half precision to the backbone model\n",
    "vit_backbone_convnext_320_focal.eval()   # Dropping unecessary layers\n",
    "model_convnext_320_focal = vit_backbone_convnext_320_focal\n",
    "model_convnext_320_focal.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84fa90ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.341045Z",
     "iopub.status.busy": "2023-10-21T11:17:28.340732Z",
     "iopub.status.idle": "2023-10-21T11:17:28.345246Z",
     "shell.execute_reply": "2023-10-21T11:17:28.344257Z"
    },
    "papermill": {
     "duration": 0.021073,
     "end_time": "2023-10-21T11:17:28.347372",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.326299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # Specify the path for the binary file\n",
    "# binary_file_path = \"/kaggle/working/model.bin\"\n",
    "\n",
    "# # Save the model's state dictionary to the binary file\n",
    "# torch.save(model, binary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1af82f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.376129Z",
     "iopub.status.busy": "2023-10-21T11:17:28.375851Z",
     "iopub.status.idle": "2023-10-21T11:17:28.380253Z",
     "shell.execute_reply": "2023-10-21T11:17:28.379411Z"
    },
    "papermill": {
     "duration": 0.02007,
     "end_time": "2023-10-21T11:17:28.382149",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.362079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# def zip_folder(folder_path, zip_filename):\n",
    "#     with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "#         for root, _, files in os.walk(folder_path):\n",
    "#             for file in files:\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 arcname = os.path.relpath(file_path, folder_path)\n",
    "#                 zipf.write(file_path, arcname)\n",
    "\n",
    "# # Replace 'your_folder_path' with the actual path to the folder you want to zip\n",
    "# folder_to_zip = '/kaggle/working'\n",
    "# output_zip_path = 'VIT-H-14.zip'\n",
    "\n",
    "# zip_folder(folder_to_zip, output_zip_path)\n",
    "\n",
    "# from IPython.display import FileLink\n",
    "\n",
    "# # Display a download link for the zip file\n",
    "# FileLink(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679fddd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.409296Z",
     "iopub.status.busy": "2023-10-21T11:17:28.408816Z",
     "iopub.status.idle": "2023-10-21T11:17:28.413051Z",
     "shell.execute_reply": "2023-10-21T11:17:28.411978Z"
    },
    "papermill": {
     "duration": 0.019803,
     "end_time": "2023-10-21T11:17:28.415068",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.395265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm model1.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be68adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.442393Z",
     "iopub.status.busy": "2023-10-21T11:17:28.442075Z",
     "iopub.status.idle": "2023-10-21T11:17:28.479566Z",
     "shell.execute_reply": "2023-10-21T11:17:28.478571Z"
    },
    "papermill": {
     "duration": 0.053561,
     "end_time": "2023-10-21T11:17:28.481678",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.428117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = get_transform()\n",
    "\n",
    "img_dir = \"/kaggle/input/vprtestdata/public_dataset/\"\n",
    "\n",
    "dataset_train = SubmissionDataset(img_dir, os.path.join(img_dir, \"gallery.csv\"), transform)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=512, num_workers=4)\n",
    "dataset_test = SubmissionDataset(img_dir, os.path.join(img_dir, \"queries.csv\"), transform, with_bbox=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=512, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c863dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.509660Z",
     "iopub.status.busy": "2023-10-21T11:17:28.509379Z",
     "iopub.status.idle": "2023-10-21T11:17:28.515377Z",
     "shell.execute_reply": "2023-10-21T11:17:28.514480Z"
    },
    "papermill": {
     "duration": 0.022036,
     "end_time": "2023-10-21T11:17:28.517268",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.495232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model_vit_h_14, model_vit_l_14, model_convnext_320_focal, weight):\n",
    "    global feature_vectors_gallery, labels_gallery\n",
    "    \n",
    "    feature_vectors_gallery, labels_gallery = get_feature_vector(model_vit_h_14, model_vit_l_14, model_convnext_320_focal, dataloader_train, weight, 1)\n",
    "    feature_vectors_query, labels_query = get_feature_vector(model_vit_h_14, model_vit_l_14, model_convnext_320_focal, dataloader_test, weight, 1)\n",
    "    \n",
    "    scores, indices = get_similiarity_l2(feature_vectors_gallery, feature_vectors_query, 1000)\n",
    "\n",
    "    indices = indices.tolist()\n",
    "    labels_gallery = labels_gallery.tolist()\n",
    "    labels_query = labels_query.tolist()\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8329f444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.544888Z",
     "iopub.status.busy": "2023-10-21T11:17:28.544611Z",
     "iopub.status.idle": "2023-10-21T11:17:28.561133Z",
     "shell.execute_reply": "2023-10-21T11:17:28.560353Z"
    },
    "papermill": {
     "duration": 0.0328,
     "end_time": "2023-10-21T11:17:28.563138",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.530338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seller_gt = pd.read_csv('/kaggle/input/vprtestdata/public_dataset/gallery.csv')\n",
    "gallery_labels = seller_gt['product_id'].values\n",
    "user_gt = pd.read_csv('/kaggle/input/vprtestdata/public_dataset/queries.csv')\n",
    "query_labels = user_gt['product_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72ec3cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T11:17:28.592321Z",
     "iopub.status.busy": "2023-10-21T11:17:28.592047Z",
     "iopub.status.idle": "2023-10-21T12:18:00.082942Z",
     "shell.execute_reply": "2023-10-21T12:18:00.081719Z"
    },
    "papermill": {
     "duration": 3631.508186,
     "end_time": "2023-10-21T12:18:00.085211",
     "exception": false,
     "start_time": "2023-10-21T11:17:28.577025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:15<00:00, 25.27s/it]\n",
      "100%|██████████| 4/4 [02:04<00:00, 31.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.38417387008667s\n",
      "Evaluation Results  of [0.7, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3777.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6074891405756979}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:10<00:00, 23.47s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.484185457229614s\n",
      "Evaluation Results  of [0.7, 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3985.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6067303264241279}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.13s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.122952699661255s\n",
      "Evaluation Results  of [0.7, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3983.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6066751177094398}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.11s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 8.885257482528687s\n",
      "Evaluation Results  of [0.7, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 4048.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.60708296114074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.24s/it]\n",
      "100%|██████████| 4/4 [02:09<00:00, 32.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.604161500930786s\n",
      "Evaluation Results  of [0.7, 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3987.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6065924389008512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.01s/it]\n",
      "100%|██████████| 4/4 [02:09<00:00, 32.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.130436420440674s\n",
      "Evaluation Results  of [0.7, 0.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3945.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6061729906908101}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.17s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.325860500335693s\n",
      "Evaluation Results  of [0.75, 0.75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3966.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6065924409556892}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.13s/it]\n",
      "100%|██████████| 4/4 [02:09<00:00, 32.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.279486179351807s\n",
      "Evaluation Results  of [0.7, 0.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3919.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6061729906908101}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.27s/it]\n",
      "100%|██████████| 4/4 [02:09<00:00, 32.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 8.73986530303955s\n",
      "Evaluation Results  of [0.9, 0.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 4022.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6067767023008861}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:15<00:00, 25.00s/it]\n",
      "100%|██████████| 4/4 [02:15<00:00, 33.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 8.774376153945923s\n",
      "Evaluation Results  of [0.7, 0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 4046.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6065345286753713}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:16<00:00, 25.58s/it]\n",
      "100%|██████████| 4/4 [02:14<00:00, 33.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.111866474151611s\n",
      "Evaluation Results  of [0.7, 0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3988.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6066156422862413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:16<00:00, 25.51s/it]\n",
      "100%|██████████| 4/4 [02:14<00:00, 33.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 8.69758677482605s\n",
      "Evaluation Results  of [1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 4093.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6074216418848573}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:16<00:00, 25.44s/it]\n",
      "100%|██████████| 4/4 [02:14<00:00, 33.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.302047729492188s\n",
      "Evaluation Results  of [0.9, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3876.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6073537796545744}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:13<00:00, 24.51s/it]\n",
      "100%|██████████| 4/4 [02:09<00:00, 32.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.102653741836548s\n",
      "Evaluation Results  of [1, 0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 4015.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6059358376719611}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.22s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.420027256011963s\n",
      "Evaluation Results  of [0.9, 0.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3744.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6075447900051979}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.11s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.274156093597412s\n",
      "Evaluation Results  of [1, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3924.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6068466442156133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:12<00:00, 24.15s/it]\n",
      "100%|██████████| 4/4 [02:08<00:00, 32.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing indices...\n",
      "Finished processing indices, took 9.145113468170166s\n",
      "Evaluation Results  of [1, 0.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1935/1935 [00:00<00:00, 3937.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mAP': 0.6073293783295821}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# weights = [[0,0],[0.2,0.2], [0.3,0.3], [0.5,0.5], [0.6,0.6], [0.7,0.7], [0.75, 0.75], [0.5,0.7], [0.6,0.7], [0.8,0.8], [0.9,0.9], [1,1]]\n",
    "weights = [[0.7,0],[0.7,0.2], [0.7,0.3], [0.7,0.5], [0.7,0.6], [0.7,0.7], [0.75, 0.75], [0.7,0.7], [0.9,0.7], [0.7,0.8], [0.7,0.9], [1,1], [0.9,0],[1,0.2], [0.9,0.3], [1,0.5], [1,0.6]]\n",
    "\n",
    "for weight in weights:\n",
    "    \n",
    "    preds = predict(model_vit_h_14, model_vit_h_14, model_convnext_320_focal, weight)\n",
    "\n",
    "#     preds_df = pd.DataFrame(preds)\n",
    "#     preds_df.to_csv('preds.csv', index=False)\n",
    "\n",
    "    # Evalaute metrics\n",
    "    print(f\"Evaluation Results  of {weight}\")\n",
    "    results = {\"mAP\": calculate_map(np.array(preds), query_labels, gallery_labels)}\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4c0d9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-21T12:18:00.174723Z",
     "iopub.status.busy": "2023-10-21T12:18:00.174352Z",
     "iopub.status.idle": "2023-10-21T12:18:00.752996Z",
     "shell.execute_reply": "2023-10-21T12:18:00.751675Z"
    },
    "papermill": {
     "duration": 0.625674,
     "end_time": "2023-10-21T12:18:00.754810",
     "exception": true,
     "start_time": "2023-10-21T12:18:00.129136",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreds_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_df' is not defined"
     ]
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10089c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.136314Z",
     "iopub.status.idle": "2023-10-21T09:52:55.136688Z",
     "shell.execute_reply": "2023-10-21T09:52:55.136536Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.136519Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evalaute metrics\n",
    "print(\"Evaluation Results\")\n",
    "results = {\"mAP\": calculate_map(np.array(preds), query_labels, gallery_labels)}\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a9f2d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.138596Z",
     "iopub.status.idle": "2023-10-21T09:52:55.138958Z",
     "shell.execute_reply": "2023-10-21T09:52:55.138805Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.138788Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluation Results - 0.75\n",
    "# # 100%|██████████| 1935/1935 [00:00<00:00, 4244.84it/s]\n",
    "# # {'mAP': 0.6066268859082989}\n",
    "\n",
    "# 100%|██████████| 3/3 [00:56<00:00, 18.86s/it]\n",
    "# 100%|██████████| 4/4 [01:20<00:00, 20.24s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.250295877456665s\n",
    "# Evaluation Results  of 0\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4115.37it/s]\n",
    "# {'mAP': 0.6076191768389487}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.72s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.87s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.076934337615967s\n",
    "# Evaluation Results  of 1\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4180.41it/s]\n",
    "# {'mAP': 0.6065552186488776}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.89s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.97s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.240142345428467s\n",
    "# Evaluation Results  of 2\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4246.23it/s]\n",
    "# {'mAP': 0.607245341224875}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.81s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.81s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.046827077865601s\n",
    "# Evaluation Results  of 3\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4158.59it/s]\n",
    "# {'mAP': 0.6064373525552245}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.80s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.89s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.576266527175903s\n",
    "# Evaluation Results  of 4\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4115.63it/s]\n",
    "# {'mAP': 0.6058129854966234}\n",
    "# 100%|██████████| 3/3 [00:48<00:00, 16.23s/it]\n",
    "# 100%|██████████| 4/4 [01:24<00:00, 21.09s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.483680963516235s\n",
    "# Evaluation Results  of 5\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 3925.31it/s]\n",
    "# {'mAP': 0.6054463695893347}\n",
    "# 100%|██████████| 3/3 [00:48<00:00, 16.06s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.90s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.089120626449585s\n",
    "# Evaluation Results  of 6\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4016.65it/s]\n",
    "# {'mAP': 0.6065924409556892}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.97s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.77s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.112382411956787s\n",
    "# Evaluation Results  of 7\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4208.87it/s]\n",
    "# {'mAP': 0.6074891405756979}\n",
    "# 100%|██████████| 3/3 [00:47<00:00, 15.74s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.93s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 5.110339879989624s\n",
    "# Evaluation Results  of 8\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4135.83it/s]\n",
    "# {'mAP': 0.606011303904902}\n",
    "# 100%|██████████| 3/3 [00:48<00:00, 16.06s/it]\n",
    "# 100%|██████████| 4/4 [01:23<00:00, 20.90s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 4.96556830406189s\n",
    "# Evaluation Results  of 9\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4257.99it/s]\n",
    "# {'mAP': 0.6073537796545744}\n",
    "\n",
    "\n",
    "\n",
    "# 100%|██████████| 3/3 [01:04<00:00, 21.59s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.41s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.623145341873169s\n",
    "# Evaluation Results  of [0, 0]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4128.46it/s]\n",
    "# {'mAP': 0.6076191768389487}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.44s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.48s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.923219680786133s\n",
    "# Evaluation Results  of [0.2, 0.2]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4122.74it/s]\n",
    "# {'mAP': 0.6072454513689215}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.51s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.45s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.427476406097412s\n",
    "# Evaluation Results  of [0.3, 0.3]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4019.73it/s]\n",
    "# {'mAP': 0.606459867453295}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.36s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.30s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.832993984222412s\n",
    "# Evaluation Results  of [0.5, 0.5]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 3979.45it/s]\n",
    "# {'mAP': 0.606632983911408}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.34s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.31s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.593319654464722s\n",
    "# Evaluation Results  of [0.6, 0.6]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4169.21it/s]\n",
    "# {'mAP': 0.6064449551494654}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.35s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.39s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.521270513534546s\n",
    "# Evaluation Results  of [0.7, 0.7]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4123.58it/s]\n",
    "# {'mAP': 0.6061729906908101}\n",
    "# 100%|██████████| 3/3 [01:06<00:00, 22.32s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.41s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.39121150970459s\n",
    "# Evaluation Results  of [0.75, 0.75]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4234.19it/s]\n",
    "# {'mAP': 0.6065924409556892}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.35s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.29s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.813293218612671s\n",
    "# Evaluation Results  of [0.5, 0.7]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4196.53it/s]\n",
    "# {'mAP': 0.60708296114074}\n",
    "# 100%|██████████| 3/3 [01:06<00:00, 22.31s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.29s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.486764430999756s\n",
    "# Evaluation Results  of [0.6, 0.7]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4005.34it/s]\n",
    "# {'mAP': 0.6065924389008512}\n",
    "# 100%|██████████| 3/3 [01:06<00:00, 22.33s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.28s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.34221339225769s\n",
    "# Evaluation Results  of [0.8, 0.8]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4144.97it/s]\n",
    "# {'mAP': 0.6070249322293987}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.47s/it]\n",
    "# 100%|██████████| 4/4 [01:57<00:00, 29.26s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.509763479232788s\n",
    "# Evaluation Results  of [0.9, 0.9]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 3989.92it/s]\n",
    "# {'mAP': 0.6067933927435037}\n",
    "# 100%|██████████| 3/3 [01:07<00:00, 22.37s/it]\n",
    "# 100%|██████████| 4/4 [01:56<00:00, 29.22s/it]\n",
    "# Processing indices...\n",
    "# Finished processing indices, took 8.44943618774414s\n",
    "# Evaluation Results  of [1, 1]\n",
    "# 100%|██████████| 1935/1935 [00:00<00:00, 4211.53it/s]\n",
    "# {'mAP': 0.6074216418848573}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed72c04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# sample image similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20664403",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.139849Z",
     "iopub.status.idle": "2023-10-21T09:52:55.140206Z",
     "shell.execute_reply": "2023-10-21T09:52:55.140030Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.140014Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(current_retrievals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb0a28",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.141276Z",
     "iopub.status.idle": "2023-10-21T09:52:55.141607Z",
     "shell.execute_reply": "2023-10-21T09:52:55.141459Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.141443Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_img(image):\n",
    "    img = image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if isinstance(img, np.ndarray):\n",
    "        img =  Image.fromarray(img)\n",
    "        \n",
    "    img = transform(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607f3b41",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.142648Z",
     "iopub.status.idle": "2023-10-21T09:52:55.142966Z",
     "shell.execute_reply": "2023-10-21T09:52:55.142818Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.142803Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@th.no_grad()\n",
    "def get_feature_vector_img(model_vit_h_14, model_vit_l_14, imgs, use_cuda=True):\n",
    "    features = []\n",
    "    if use_cuda:\n",
    "        imgs = imgs.cuda()\n",
    "    x = (model(imgs.half())).detach().cpu().numpy().astype(np.float32)  # .half()\n",
    "    print(model(imgs.half()).shape)\n",
    "    features.append(x)\n",
    "\n",
    "    return np.concatenate(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac710a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.143962Z",
     "iopub.status.idle": "2023-10-21T09:52:55.144336Z",
     "shell.execute_reply": "2023-10-21T09:52:55.144154Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.144114Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = '/kaggle/input/vprtestdata/public_dataset/queries/accelerated-glorious-fennec-of-reward.jpg'\n",
    "\n",
    "def get_similar_prods(img_path):\n",
    "\n",
    "    image = read_image(img_path)\n",
    "    image = transform_img(image)\n",
    "    image = image.unsqueeze(dim=0)\n",
    "#     feature_vectors_gallery, labels_gallery = get_feature_vector(model, dataloader_train, 1)\n",
    "    feature_vectors_query = get_feature_vector_img(model_vit_h_14, model_vit_l_14, image, 1)\n",
    "    scores, indices = get_similiarity_l2(feature_vectors_gallery, feature_vectors_query, 1000)\n",
    "    preds = convert_indices_to_labels(indices, labels_gallery)\n",
    "    indices = indices.tolist()\n",
    "\n",
    "    return [indices , preds]\n",
    "    \n",
    "[similar_images, labels] = get_similar_prods(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e6d2d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.145630Z",
     "iopub.status.idle": "2023-10-21T09:52:55.145972Z",
     "shell.execute_reply": "2023-10-21T09:52:55.145823Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.145807Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path_q = '/kaggle/input/vprtestdata/public_dataset/queries.csv'  \n",
    "data_q = pd.read_csv(csv_path_q)\n",
    "\n",
    "x = data_q[data_q['img_path'] == 'queries/accelerated-glorious-fennec-of-reward.jpg']\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d6a55",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.146860Z",
     "iopub.status.idle": "2023-10-21T09:52:55.147232Z",
     "shell.execute_reply": "2023-10-21T09:52:55.147053Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.147037Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_df1 = pd.DataFrame(similar_images)\n",
    "\n",
    "preds_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0d754",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.149171Z",
     "iopub.status.idle": "2023-10-21T09:52:55.149508Z",
     "shell.execute_reply": "2023-10-21T09:52:55.149360Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.149344Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.savefig('query.png')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1eda6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.152680Z",
     "iopub.status.idle": "2023-10-21T09:52:55.153031Z",
     "shell.execute_reply": "2023-10-21T09:52:55.152881Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.152865Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "csv_path = '/kaggle/input/vprtestdata/public_dataset/gallery.csv'  \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "prod_ids = similar_images[0][:100]  \n",
    "\n",
    "num_images = len(prod_ids)\n",
    "num_columns = 10\n",
    "num_rows = (num_images + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 15))\n",
    "\n",
    "for i, prod_id in enumerate(prod_ids):\n",
    "    row = data[data['seller_img_id'] == prod_id]\n",
    "    \n",
    "    if not row.empty:\n",
    "        image_path = '/kaggle/input/vprtestdata/public_dataset/' + row.iloc[0]['img_path']\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        img = img.resize((224, 224))\n",
    "        \n",
    "        row_idx = i // num_columns\n",
    "        col_idx = i % num_columns\n",
    "        \n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Image ID: {prod_id}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "for i in range(num_images, num_rows * num_columns):\n",
    "    fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('inference.png')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d918677",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.154340Z",
     "iopub.status.idle": "2023-10-21T09:52:55.154662Z",
     "shell.execute_reply": "2023-10-21T09:52:55.154523Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.154508Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download custom image\n",
    "# import requests\n",
    "\n",
    "# # Setup custom image path\n",
    "# custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
    "\n",
    "# # Download the image if it doesn't already exist\n",
    "# if not custom_image_path.is_file():\n",
    "#     with open(custom_image_path, \"wb\") as f:\n",
    "#         # When downloading from GitHub, need to use the \"raw\" file link\n",
    "#         request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
    "#         print(f\"Downloading {custom_image_path}...\")\n",
    "#         f.write(request.content)\n",
    "# else:\n",
    "#     print(f\"{custom_image_path} already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954e9c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-21T09:52:55.156385Z",
     "iopub.status.idle": "2023-10-21T09:52:55.156714Z",
     "shell.execute_reply": "2023-10-21T09:52:55.156568Z",
     "shell.execute_reply.started": "2023-10-21T09:52:55.156553Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.transforms.functional import resize, normalize\n",
    "from open_clip import create_model_and_transforms, tokenize\n",
    "\n",
    "\n",
    "class CLIP64(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, dimensionality_reduction='PCA'):\n",
    "        \"\"\"\n",
    "        Load a CLIP model and append a PCA layer or a random choice among the head neurons to obtain a 64D vector \n",
    "        The PCA is obtained on embeddings of plausible labels generated by GPT-3\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dimensionality_reduction = dimensionality_reduction\n",
    "\n",
    "        # Load model and transforms\n",
    "        model, transforms, _ = create_model_and_transforms(model_name, pretrained, jit=False, device='cuda')\n",
    "\n",
    "        # Transforms parameters\n",
    "        self.image_size = transforms.transforms[0].size[0]\n",
    "        self.mean = transforms.transforms[-1].mean\n",
    "        self.std = transforms.transforms[-1].std\n",
    "\n",
    "        # PCA using GPT-3 captions\n",
    "        if self.dimensionality_reduction == 'PCA':\n",
    "            W_text = []\n",
    "            url = 'https://raw.githubusercontent.com/IvanAer/G-Universal-CLIP/main/media/GPT3_words.json'\n",
    "            gpt3_words = requests.get(url).json()\n",
    "            for word in gpt3_words:\n",
    "                w = tokenize(word)\n",
    "                w = model.encode_text(w.to('cuda'))[0].detach().cpu()\n",
    "                w /= w.norm()\n",
    "                w = w.numpy()\n",
    "                W_text.append(w)\n",
    "            pca = PCA(64, whiten=True)\n",
    "            pca.fit(W_text)\n",
    "            self.pca_components = torch.Tensor(pca.components_).half().to('cuda')\n",
    "            self.pca_mean = torch.Tensor(pca.mean_).half().to('cuda')\n",
    "        elif self.dimensionality_reduction == 'random':\n",
    "            W = model.visual.proj.detach().cpu().numpy()\n",
    "            mask64 = np.random.permutation(W.shape[1])[:64]\n",
    "            model.visual.proj = nn.Parameter(torch.tensor(W[:, mask64]).half().to('cuda'))\n",
    "            # Needed for torchscript\n",
    "            self.pca_components = torch.Tensor(np.zeros((W.shape[1], 1))).half().to('cuda')\n",
    "            self.pca_mean = torch.Tensor(np.zeros(W.shape[1])).half().to('cuda')\n",
    "            \n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        # Set encoder\n",
    "        self.encoder = model.visual.half().eval()\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        The input image is padded and resized to the size required by the CLIP visual encoder\n",
    "        The PCA layer is then applied to the output of the encode\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad\n",
    "        h, w = image.size()[2:]\n",
    "        p_left, p_top = [(max(h, w) - s) // 2 for s in [h, w]]\n",
    "        p_right, p_bottom = [max(h, w) - (s + pad) for s, pad in zip([h, w], [p_left, p_top])]\n",
    "        value = 255. * sum(self.mean) / 3\n",
    "        image = nn.functional.pad(image, [p_top, p_bottom, p_left, p_right], 'constant', value)\n",
    "\n",
    "        # Resize\n",
    "        image = resize(image, size=(self.image_size, self.image_size), interpolation=InterpolationMode.BICUBIC)\n",
    "\n",
    "        # Normalize\n",
    "        image = image.half()\n",
    "        image /= 255.\n",
    "        image = normalize(image, mean=self.mean, std=self.std)\n",
    "\n",
    "        # Run feature extractor\n",
    "        features = self.encoder(image.to('cuda'))[0]\n",
    "\n",
    "        # Apply dimensionality reduction\n",
    "        features /= features.norm()\n",
    "        if self.dimensionality_reduction == 'PCA':\n",
    "            features = self.pca_components @ (features - self.pca_mean)\n",
    "        features = features.unsqueeze(0)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "# Load model\n",
    "#model = CLIP64('ViT-H-14', 'laion2b_s32b_b79k', 'random')\n",
    "model = CLIP64('ViT-H-14', 'laion2b_s32b_b79k', 'PCA')\n",
    "\n",
    "# Save it\n",
    "model = torch.jit.script(model)\n",
    "model.save('saved_model.pt')\n",
    "\n",
    "with ZipFile('submission.zip', 'w') as z:\n",
    "    z.write('saved_model.pt', arcname='saved_model.pt')\n",
    "    \n",
    "    \n",
    "# Sanity check using challenge code\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Model loading\n",
    "model = torch.jit.load('saved_model.pt')\n",
    "model.eval()\n",
    "embedding_fn = model\n",
    "\n",
    "# Load image and extract its embedding.\n",
    "url = 'https://images-eu.ssl-images-amazon.com/images/I/712Qd71eiYL.__AC_SY300_SX300_QL70_ML2_.jpg'\n",
    "input_image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "convert_to_tensor = transforms.Compose([transforms.PILToTensor()])\n",
    "input_tensor = convert_to_tensor(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    embedding = torch.flatten(embedding_fn(input_batch)[0]).cpu().data.numpy()\n",
    "    \n",
    "print(input_image.size)\n",
    "print(embedding.shape)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49235f2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3725.53616,
   "end_time": "2023-10-21T12:18:04.377664",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-21T11:15:58.841504",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
